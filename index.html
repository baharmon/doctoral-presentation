<!doctype html>
<html lang="en">
<!-- This is a generated file. Do not edit. -->

    <head>
        <meta charset="utf-8">

        <title>Tangible Landscape &#64; TEI 2016</title>

        <meta name="description" content="Embodied Cognition with Tangible Landscape">
        <meta name="author" content="Brendan Harmon">

        <meta name="apple-mobile-web-app-capable" content="yes" />
        <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

        <link rel="stylesheet" href="css/reveal.css">
        <link rel="stylesheet" href="css/theme/osgeorel_greyscale.css" id="theme">
        <link rel="stylesheet" href="lib/fonts/font-awesome/css/font-awesome.min.css">
        <link rel="stylesheet" href="lib/fonts/lato/latofonts.css" type="text/css">

        <!-- For syntax highlighting -->
        <link rel="stylesheet" href="lib/css/zenburn.css">

        <!-- If the query includes 'print-pdf', include the PDF print sheet -->
        <script>
            if( window.location.search.match( /print-pdf/gi ) ) {
                var link = document.createElement( 'link' );
                link.rel = 'stylesheet';
                link.type = 'text/css';
                link.href = 'css/print/pdf.css';
                document.getElementsByTagName( 'head' )[0].appendChild( link );
            }
        </script>

        <!--[if lt IE 9]>
        <script src="lib/js/html5shiv.js"></script>
        <![endif]-->

        <style>
        body {
        /*background-color: #FFF !important;*/
        /*
          background-image: url("pictures/elevation-nagshead.gif");
          background-repeat: no-repeat;
          background-position: left bottom;*/
        }
        .reveal section img {
            background: transparent;
            border: 0;
            box-shadow: 0 0 0 rgba(0, 0, 0, 0.15);
        }
        /* for standalone frame */
        /*
        iframe {
            display: block;
            margin-left: auto;
            margin-right: auto;
        }
        */
        /* display: inline; background-color: #002B36; padding: 0px; margin: 0px */
        .rounded-corners {
            border: 0px solid black;
            border-radius: 5px;
            -moz-border-radius: 5px;
            -khtml-border-radius: 5px;
            -webkit-border-radius: 5px;
        }
        a {
            color: #444 !important;
        }
        a:hover {
            color: #444 !important;
            text-decoration: underline !important;
        }
        h1, h2, h3, h4, h5 {
            text-transform: none !important;
            /* word-break: keep-all; text-transform: none; font-size: 200%; line-height: 110%; font-weight: bold !important; */
            /* color: #060 !important; */
            /* color: #444 !important; */
            -webkit-hyphens: none !important;
            -moz-hyphens: none !important;
            -ms-hyphens: none !important;
            hyphens: none !important;
            line-height: 110% !important;
        }
        .reveal .progress span {
            background-color: #444 !important;
        }
        /* predefined element positioning */
        .top {
            /*position: relative;*/
            top: 5%;
            height: 45%; /* is the height even needed? */
        }
        .bottom {
            height: 45%;
        }
        .ne {
            position: absolute;
            top: 5%;
            right: 5%;
            height: 45%;
            width: 45%;
        }
        .nw {
            position: absolute;
            top: 5%;
            left: 5%;
            height: 45%;
            width: 45%;
        }
        .se {
            position: absolute;
            bottom: 5%;
            right: 5%;
            height: 45%;
            width: 45%;
        }
        .sw {
            position: absolute;
            bottom: 5%;
            left: 5%;
            height: 45%;
            width: 45%;
        }

        /* classes for sections with predefined elements */
        /* using !important because, reveal styles are applied afterwards  */
        .right, .textimg > img, .textimg > video, .textimg > iframe, .imgtext > p, .imgtext > ul, .imgtext > ol, .imgtext > div {
            float: right;
            text-align: left;
            max-width: 47% !important;
        }
        .left, .imgtext > img, .imgtext > video, imgtext > iframe, .textimg > p, .textimg > ul, .textimg > ol, .textimg > div {
            float: left;
            text-align: left;
            max-width: 47% !important;
        }
        li > ul, li > ol {
            font-size: 85% !important;
            line-height: 110% !important;
        }
        .small {
            font-size: smaller !important;
            color: gray;
            margin: 0.1em !important;
        }
        .credit {
            font-size: small !important;
            color: gray;
            margin: 0.1em !important;
        }
        </style>
    </head>

    <body>

        <div class="reveal">

            <!-- Any section element inside of this container is displayed as a slide -->
            <div class="slides">

<!-- Title -->
<section>
<img height="250px" src="img/tl_logo.png">
<h4 style="color: #888">Brendan Harmon</h4>
</section>

<!-- Spatial thinking -->
<section>
<h2>Spatial thinking</h2>
<p>`the mental processes of representing, analyzing, and drawing inferences from spatial relations'</p>
<p style="font-size:0.75em">Uttal, D. H., Miller, D. I., &amp Newcombe, N. S. (2013). <i>Exploring and Enhancing Spatial Thinking: Links to Achievement in Science, Technology, Engineering, and Mathematics?</i> Current Directions in Psychological Science, 22(5), 367–373. doi:10.1177/0963721413484756</a></p>
</section>

<!-- Spatial thinking -->
<section>
<h2>Spatial thinking</h2>
<p>Used pervasively in everyday life for tasks like
<ul>
<li>recognizing things,</li>
<li>manipulating things,</li>
<li>interacting with others,</li>
<li>and way-finding</li>
</ul>
</p>
</section>

<!-- Spatial thinking -->
<section data-background="img/jockeys_ridge_viz.jpg">
<h2 class="shadow">Spatial thinking in science, technology, engineering, and math</h2>
<p class="shadow">Used in diverse tasks including
<ul class="shadow">
<li>diagramming concepts,</li>
<li>visualizing data,</li>
<li>simulating processes,</li>
<li>and building structures</li>
</ul>
</p>
</section>

<!-- Spatial thinking -->
<section data-background="img/drawing_1.jpg">
<h2 class="shadow">Spatial thinking in art and design</h2>
<p class="shadow">Used in tasks including
<ul class="shadow">
<li>sketching,</li>
<li>form-finding,</li>
<li>and critical analysis</li>
</ul>
</p>
</section>

<!-- Spatial computation -->
<section data-background="img/skyview.png">
<h2 class="shadow">Spatial computation</h2>
<h3 class="shadow">Used to efficiently store, model, and analyze large sets of spatial data in order solve complex spatiotemporal problems</h3>
</section>

<!-- Human-computer interaction -->
<section>
<h2>Human-computer interaction</h2>
<h3 style="color: #888">Graphical user interfaces</h3>
<p>Parsing spatial data presented graphically requires sophisticated reasoning such as
<ul>
<li>mental rotation,</li>
<li>spatial visualization,</li>
<li>and spatial perception</li>
</ul>
</p>
</section>

<!-- Embodied cognition -->
<section data-background="img/physical_rotation_2.jpg">
<h2 class="shadow">Embodied cognition</h2>
<h3 class="shadow">Cognitive processes can be offloaded onto the body and physically simulated</h3>
<p class="shadow">Ex: Physically simulating mental rotation</p>
</section>

<!-- Tangible interface for GIS -->
<section>
<h2>Tangible interfaces for GIS</h2>
<p>Physically manifest geospatial data so that we can cognitively grasp and absorb it<p>
<img height="250px" src="img/logo_black.png">
<img height="250px" src="img/tl_logo.png">
</section>

<!-- Tangible Landscape -->
<section data-background="img/tangible_landscape.jpg">
<h1 class="shadow">Tangible Landscape</h1>
<h3 class="shadow">A tangible interface for GIS</h3>
<img height="150px" src="img/logo_black.png">
</section>

<!-- Tangible Landscape -->
<section data-background="img/tl_system_logo.png" data-background-size="auto 75%">
</section>

<!-- History -->
<section>
<h2>History</h2>
<img height="250px" src="img/illuminating_clay.png">
<img height="250px" src="img/tangeoms_2.jpg">
<p>An evolution of <b>Illuminating Clay</b> and the <b>Tangible Geospatial Modeling System</b></p>
<p style="font-size:0.75em"><a href="http://tmg-trackr.media.mit.edu/publishedmedia/Papers/249-Illuminating%20Clay%20A%20Tangible/Published/PDF">Piper, Ben, Carlo Ratti, and Hiroshi Ishii. 2002. “Illuminating Clay: A Tangible Interface with Potential GRASS Applications.” In Proceedings of the Open Source GIS - GRASS Users Conference 2002. Trento, Italy.</a></p>
<p style="font-size:0.75em"><a href="http://baharmon.github.io/publications/tangible_geospatial_modeling.pdf">L. Tateosian, H. Mitasova, B. A. Harmon, B. Fogleman, K. Weaver, and R. S. Harmon, “TanGeoMS: tangible geospatial modeling system.,” IEEE Trans. Vis. Comput. Graph., vol. 16, no. 6, pp. 1605–12, 2010.</a></p>
<p style="font-size:0.75em">Image source: <a href="http://tangible.media.mit.edu/project/illuminating-clay/">MIT Media Lab</a></p>
</section>

<!-- Near real time interaction -->
<section>
<h2>Tanigble interaction with GIS</h2>
<video  data-autoplay width="90%" style="margin-top: 1em" controls>
<source src="img/tl_dam.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>With Tangible Landscape you can hold a GIS in your hands - feeling the shape of the earth, sculpting its topography, and directing the flow of water.</p>
</section>

<!-- How it works -->
<section>
<h2>How-it-works</h2>
<img style="margin-top: 1em" height="500px" src="img/system_schema.png">
<p>Tangible Landscape couples a digital and a physical model through a continuous cycle of 3D scanning, geospatial modeling, and projection</p>
</section>

<!-- Science with Tangible Landscape -->
<section>
<h2>Intuitive scientific modeling</h2>
<img width="25%" src="img/subsurface_1.jpg">
<img width="25%" src="img/subsurface_2.jpg">
<img width="40.55%" src="img/subsurface_3.jpg">
<h4>Tangible Landscape is designed to make scientific models exploratory, engaging, and fun</h4>
<p>by enabling a rapid iterative process of observation, hypothesizing, testing, and inference</p>
</section>

<!-- Designing for performance -->
<section>
<h2>Geodesign</h2>
<img src="img/diagram_1.png">
<h3 style="margin-top: 0.25em">Designing performance landscapes</a></h3>
<h4 style="margin-top: 0.75em">through an iterative cycle of ideation, geospatial modeling, and critique</h4>
</section>

<!-- Visibility analysis -->
<section>
<h2>Applications</h2>
<video  data-autoplay width="90%" style="margin-top: 1em" controls>
<source src="img/visibility.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<h4 style="margin-top: 1em">Visibility analysis</h4>
</section>

<!-- Solar analysis-->
<section>
<h2>Applications</h2>
<img width="30%" src="img/solar_1.jpg">
<img width="30%" src="img/solar_2.jpg">
<img width="30%" src="img/solar_3.jpg">
<h4 style="margin-top: 1em">Solar analysis</h4>
<p>Solar irradiation and cast shadow</p>
</section>

<!-- Trail Planning -->
<section>
<h2>Applications</h2>
<img width="30%" src="img/trail_1.jpg">
<img width="30%" src="img/trail_2.jpg">
<img width="30%" src="img/trail_4.jpg">
<!--<img width="24%" src="img/trail_5.jpg">-->
<h4 style="margin-top: 1em">Trail planning</h4>
<p>Optimized trail routing between waypoints based on energetics, topography, and cost maps with feedback including trail slopes and viewsheds</p>
</section>

<!-- Serious gaming with Tangible Landscape: Coastal -->
<section>
<h2>Scientific gaming</h2>
<img width="30%" src="img/tl_coastal_1s.png">
<img width="30%" src="img/tl_coastal_2s.png">
<!--<img width="22%" src="img/tl_coastal_3s.png">-->
<img width="30%" src="img/tl_coastal_4s.png">
<h3 style="margin-top: 1em">Coastal flooding game</h3>
<h4>Save houses from coastal flooding by building coastal defenses</h4>
<p>Structured problem solving with rules, challenging objectives, and scoring</p>
</section>

<!-- Serious gaming with Tangible Landscape: Termites -->
<section>
<h2>Scientific gaming</h2>
<img width="30%" src="img/termite_game_1.jpg">
<img width="30%" src="img/termite_game_2.jpg">
<img width="30%" src="img/termite_game_3.jpg">
<h3 style="margin-top: 1em">Termite infestation game</h3>
<h4>Manage the spread of termites across a city by treating city blocks</h4>
<p>Explore the behavior of an epidemiological model through serious gaming</p>
</section>

<!-- Experiment -->

<!-- Research questions -->
<section>
<h2>Research questions</h2>
<p>
<ul>
<li>How can we design an effective tangible interface for GIS?</li>
<li>Can coupling a physical and digital model of topography improve spatial performance?</li>
<li>How do different geospatial analytics mediate users' spatial performance when using a tangible interface for GIS?</li>
</ul>
</p>
</section>

<!-- Coupling -->
<section>
<h2>Coupling experiment</h2>
<img width="30%" src="img/anderson_rhino.jpg">
<img width="30%" src="img/magallanes_hand.jpg">
<img width="30%" src="img/art_proj_aug.jpg">
<h4 style="margin-top: 1em">Can coupling a physical and digital model of topography improve spatial performance?</h4>
<p>A comparative study of 3D spatial performance with 1. digital modeling, 2. hand modeling, and 3. projection augmented modeling</p>
</section>

<!-- Coupling: mean elevation -->
<section>
<h2>Mean elevation</h2>
<img width="22.5%" src="img/results/dem_1.png">
<img width="22.5%" src="img/results/mean_dem_1.png">
<img width="22.5%" src="img/results/mean_dem_2.png">
<img width="22.5%" src="img/results/mean_dem_3.png">
<h4 style="margin-top: 1em"></h4>
<p>1. reference,  2. digital modeling, 3. hand modeling, and 4. projection augmented modeling</p>
</section>

<!-- Coupling: elevation difference -->
<section>
<h2>Mean difference in elevation</h2>
<img width="22.5%" src="img/results/dem_difference_1.png">
<img width="22.5%" src="img/results/mean_dem_difference_1.png">
<img width="22.5%" src="img/results/mean_dem_difference_2.png">
<img width="22.5%" src="img/results/mean_dem_difference_3.png">
<h4 style="margin-top: 1em"></h4>
<p>1. reference,  2. digital modeling, 3. hand modeling, and 4. projection augmented modeling</p>
</section>

<!-- Coupling: slope difference -->
<section>
<h2>Mean difference in slopes</h2>
<img width="22.5%" src="img/results/slope_difference_1.png">
<img width="22.5%" src="img/results/mean_slope_difference_1.png">
<img width="22.5%" src="img/results/mean_slope_difference_2.png">
<img width="22.5%" src="img/results/mean_slope_difference_3.png">
<h4 style="margin-top: 1em"></h4>
<p>1. reference,  2. digital modeling, 3. hand modeling, and 4. projection augmented modeling</p>
</section>

<!-- Coupling: depth difference -->
<section>
<h2>Mean difference in water depth</h2>
<img width="22.5%" src="img/results/depth_difference_1.png">
<img width="22.5%" src="img/results/mean_depth_difference_1.png">
<img width="22.5%" src="img/results/mean_depth_difference_2.png">
<img width="22.5%" src="img/results/mean_depth_difference_3.png">
<h4 style="margin-top: 1em"></h4>
<p>1. reference,  2. digital modeling, 3. hand modeling, and 4. projection augmented modeling</p>
</section>

<!-- Coupling: landforms difference
<section>
<h2>Mean difference in landforms</h2>
<img width="22.5%" src="img/results/forms_difference_1.png">
<img width="22.5%" src="img/results/mean_forms_difference_1.png">
<img width="22.5%" src="img/results/mean_forms_difference_2.png">
<img width="22.5%" src="img/results/mean_forms_difference_3.png">
<h4 style="margin-top: 1em"></h4>
<p>1. reference,  2. digital modeling, 3. hand modeling, and 4. projection augmented modeling</p>
</section>
 -->

<!-- Coupling: ridges difference -->
<section>
<h2>Mean difference in ridges</h2>
<img width="22.5%" src="img/results/ridges_1.png">
<img width="22.5%" src="img/results/mean_ridges_1.png">
<img width="22.5%" src="img/results/mean_ridges_2.png">
<img width="22.5%" src="img/results/mean_ridges_3.png">
<h4 style="margin-top: 1em"></h4>
<p>1. reference,  2. digital modeling, 3. hand modeling, and 4. projection augmented modeling</p>
</section>

<!-- Difference -->
<section>
<h2>Cut-fill experiment</h2>
<video  data-autoplay width="90%" style="margin-top: 1em" controls>
<source src="img/difference_analytic.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<h4>Building a terrain model in polymer-enriched sand using Tangible Landscape's differencing analytic (i.e. cut and fill) as a real-time guide.</h4>
<p>Blue means add more sand. Red means remove sand.</p>
</section>

<!-- Difference -->
<section>
<h2>Cut-fill experiment</h2>
<img width="22.5%" src="img/difference/tl_difference_1.jpg">
<img width="22.5%" src="img/difference/tl_difference_2.jpg">
<img width="22.5%" src="img/difference/tl_difference_3.jpg">
<img width="22.5%" src="img/difference/tl_difference_4.jpg">
<p style="margin-top: 1em">How does the difference analytic (ie. cut-fill) mediate users' spatial performance with a tangible interface for GIS?</p>
</section>

<!-- Difference: mean elevation -->
<section>
<h2>Mean elevation</h2>
<img width="48%" src="img/results/dem_4.png">
<img width="48%" src="img/results/mean_dem_4.png">
<h4 style="margin-top: 1em"></h4>
<p>1. reference and 2. cut-fill analytic</p>
</section>

<!-- Difference: elevation difference -->
<section>
<h2>Mean difference in elevation</h2>
<img width="48%" src="img/results/dem_difference_4.png">
<img width="48%" src="img/results/mean_dem_difference_4.png">
<h4 style="margin-top: 1em"></h4>
<p>1. reference and 2. cut-fill analytic</p>
</section>

<!-- Water flow -->
<section data-background="img/tl_water.jpg">
<h2 class="shadow">Water flow experiment</h2>
<p class="shadow" style="margin-top: 1em">How does the water flow analytic mediate users' spatial performance with a tangible interface for GIS?</p>
</section>


<!-- Water flow: depth -->
<section>
<h2>Mean water depth</h2>
<img width="48%" src="img/results/depth_5.png">
<img width="48%" src="img/results/mean_depth_5.png">
<h4 style="margin-top: 1em"></h4>
<p>1. reference and 2. water flow analytic</p>
</section>

<!-- Water flow: flow difference -->
<section>
<h2>Mean difference in water depth</h2>
<img width="48%" src="img/results/depth_difference_5.png">
<img width="48%" src="img/results/mean_depth_difference_5.png">
<h4 style="margin-top: 1em"></h4>
<p>1. reference and 2. water flow analytic</p>
</section>

<!-- Findings -->
<section>
<h2>Findings</h2>
<ul>
<li>This method of digital modeling tended to produce abstract approximations of the form</li>
<li>Hand modeling tended to produce rough, exaggerated models that represented many morphological features</li>
<li>Projection augemented modeling tended to produce relatively accurate models that better represented slope, water flow, and morphological features</li>
<li>The cut-fill analytic tended to produce very accurate models</li>
<li>The water flow analytic tended to produce accurately modeled stream channels, but more approximate topography elsewhere</li>
</ul>
</section>

<!-- Discussion -->
<section>
<h2>Observations</h2>
<ul>
<li>The cut-fill analytic enabled participants to generatively shape form and critically assess the results in an iterative cycle</li>
<li>The water flow simulation enabled an iterative cycle of form-finding and critical assessment that helped participants to learn how form controls process</li>
</ul>
</section>

<!-- Conclusion -->
<section>
<h2>Conclusions</h2>
<ul>
<li>Tangible Landscape encourages metacognitive processes</li>
<li>Tangible Landscape can increase users' spatial performance in different ways depending upon the analytics choosen</li>
<li>Tangible Landscape can help users link process to form</li>
</ul>
</section>

<!-- Implications -->
<section>
<h2>Implications</h2>
<ul>
<li>The cut-fill and water flow analytics could be used to teach grading and geomorphology</li>
</ul>
</section>

<!-- Summary -->

<!-- Publications -->
<section>
<h2>Publications</h2>
<ul>
<li>
Harmon, B. A., Petrasova, A., Petras, V., &amp Mitasova, H. (2016).
Computational Landscape Architecture: Procedural, Tangible, and Open Landscapes.
In J. R. Anderson & D. Ortega (Eds.), <a href="https://www.routledge.com/Innovations-in-Landscape-Architecture/Anderson-Ortega/p/book/9781138860681"><em>Innovations in Landscape Architecture</em></a>. Routledge.
</li>
<li>
Harmon, B. A., Petrasova, A., Petras, V., Mitasova, H., &amp Meentemeyer, R. K. (2016).
<a href="https://github.com/baharmon/isprs-2016/blob/master/isprs_2016.pdf">Tangible Landscape: cognitively grasping the flow of water</a>.
In <em>The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences</em>.
Prague: International Society of Photogrammetry and Remote Sensing.
</li>
<li>
Harmon, B. A. (2016).
<a href="http://dx.doi.org/10.1145/2839462.2854103">Embodied Spatial Thinking in Tangible Computing.</a>
In <em>TEI ’16: Proceedings of the Tenth International Conference on Tangible, Embedded, and Embodied Interaction </em> (pp. 693–696). Eindhoven, Netherlands: ACM Press. <a href="http://dx.doi.org/10.1145/2839462.2854103">http://dx.doi.org/10.1145/2839462.2854103</a>
</li>
<li>
Petrasova, A., Harmon, B., Petras, V., &amp Mitasova, H. (2015).
<em>Tangible Modeling with Open Source GIS.</em> Springer International Publishing.
<a href="http://dx.doi.org/10.1007/978-3-319-25775-4">http://dx.doi.org/10.1007/978-3-319-25775-4</a>
</li>
<li>
Petrasova, A., Harmon, B. A., Petras, V., &amp Mitasova, H. (2014).
<a href="http://www.iemss.org/sites/iemss2014/papers/iemss2014_submission_131.pdf">GIS-based environmental modeling with tangible interaction and dynamic visualization</a>.
In D. P. Ames &amp N. Quinn (Eds.), <em>Proceedings of the 7th International Congress on Environmental Modelling and Software</em>.
San Diego, California, USA: International Environmental Modelling and Software Society.
</li>
</ul>
</section>

<section>
<h2>Presentations</h2>
<ul>
<li>
Petrasova, A., Petras, V., Harmon, B. A., &amp Mitasova, H. (2016, May 2).
<a href="https://grasswiki.osgeo.org/wiki/Using_GRASS_GIS_through_Python_and_tangible_interfaces_(workshop_at_FOSS4G_NA_2016)"><em>Using GRASS GIS through Python and tangible interfaces</em></a>.
Workshop conducted at FOSS4G North America 2016, Raleigh, NC.
</li>
<li>
Harmon, B. A., Petrasova, A., Petras, V., Mitasova, H., &amp Meentemeyer, R. K. (2016, May 3).
<a href="http://baharmon.github.io/foss4g-na-2016/"><em>Tangible interaction for GIS</em></a>.
Presented at FOSS4G NA 2016, Raleigh, NC.
</li>
<li>
Harmon, B. A., Petrasova, A., Petras, V., Mitasova, H., &amp Meentemeyer, R. K. (2016, April 1).
<a href="http://baharmon.github.io/aag-2016/"><em>Creative spatial thinking with Tangible Landscape</em></a>.
Presented at American Association of Geographers Annual Meeting 2016, San Francisco, CA.
</li>
<li>
Harmon, B. A., Mitasova, H., &amp Petrasova, A. (2014, January 30).
<a href="http://video.esri.com/watch/3170/tangible-geospatial-modeling-for-landscape-architects"><em>Tangible geospatial modeling for landscape architects.</em></a>
Presented at 2014 Geodesign Summit, Redlands, CA.
</li>
</ul>
</section>

<!-- Timeline -->


<!-- Future work -->

<!-- Future work: cognitive science -->
<section data-background="img/tl_cog_sci.png">
<h2 class="shadow">Future work</h2>
<p class="shadow" style="margin-top: 1em">Cognitive science experiments to study metacognition and learning with Tangible Landscape</p>
</section>

<!-- Future work: in-situ digital fabrication -->
<section>
<h2>Future work</h2>
<video  data-autoplay width="90%" style="margin-top: 1em" controls>
<source src="img/cnc_sand.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<h4>In-situ digital fabrication</h4>
<p>A 3-axis CNC milling machine to model a landscape in polymer-enriched sand using a plunge cut</p>
</section>

<!-- Future work: robotic fabrication -->
<section>
<h2>Future work</h2>
<img style="margin-top: 1em" height="500px" src="img/system_schema_robot.png">
<p>In-situ robotic fabrication for Tangible Landscape</p>
</section>

<!-- Future work: VR -->
<section>
<h2>Future work</h2>
<img style="margin-top: 1em" height="500px" src="img/system_schema_vr.png">
<p>Virtual reality for Tangible Landscape</p>
</section>

<!-- Future work: autonomous construction -->
<section>
<h2>Future work</h2>
<img style="margin-top: 1em" width="100%" src="img/system_schema_land.png">
<p>Real-time data and autonomous construction with Tangible Landscape</p>
</section>

<!-- Experiment: open science
<section>
<h2>Open science</h2>
<img width="10%" src="img/Octocat.png">
<h4 style="margin-top: 1em">Fork us on GitHub</h4>
<p><a href="https://github.com/baharmon/tangible_topography">Repository with experiment instructions, scripts, data, and results</a></p>
<p><a href="https://github.com/ncsu-osgeorel/grass-tangible-landscape">Repository for the Tangible Landscape plugin for GRASS GIS</a></p>
</section>
-->

<!-- Open education
<section>
<h2>Open education</h2>
<img height="150px" src="img/logo_black.png">
<h4 style="margin-top: 1em">Open source software, open algorithms, open data, and open educational resources</h4>
<p>
Petras, V., Petrasova, A., Harmon, B., Meentemeyer, R.K., Mitasova, H.
<a href="http://www.mdpi.com/2220-9964/4/2/942/pdf"><em>
Integrating Free and Open Source Solutions into Geospatial Science Education</em></a>.
ISPRS International Journal of Geo-Information. 2015, 4, 942-956.
<a href="http://dx.doi.org/10.3390/ijgi4020942">doi:10.3390/ijgi4020942</a>
</p>
</section>
-->

<!-- Book
<section>
<h2>Set up your own system</h2>
<img width="20%" src="img/tl_book_cover.png">
<p>Read our <a href="http://www.springer.com/us/book/9783319257730">book</a> and give it a try</p>
</section>
-->

<!-- Future work: cognitive science
<section>
<h2>Future work</h2>
<img width="90%" src="img/future_system.png">
<p>Experiments using eye trackers, EEGs, and biometric sensors to study learning and creativity with Tangible Landscape</p>
</section>
-->

<!-- Future work: digital fabrication
<section>
<h2>Future work</h2>
<video  data-autoplay width="90%" style="margin-top: 1em" controls>
<source src="img/cnc_sand.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>In situ digital fabrication</p>
</section>
-->

<!-- Discussion -->
<!-- This is a generated file. Do not edit. -->
        </div>  <!-- slides -->

    </div>  <!-- reveal -->

        <script src="lib/js/head.min.js"></script>
        <script src="js/reveal.js"></script>

        <script>

            // Full list of configuration options available here:
            // https://github.com/hakimel/reveal.js#configuration
            Reveal.initialize({
                // Display controls in the bottom right corner
                controls: false,

                // Display a presentation progress bar
                progress: true,
                
                center: true,
                
                // Display the page number of the current slide
                slideNumber: false,

                // Enable the slide overview mode
                overview: true,

                // Turns fragments on and off globally
                fragments: true,

                // The "normal" size of the presentation, aspect ratio will be preserved
                // when the presentation is scaled to fit different resolutions. Can be
                // specified using percentage units.
                // width: 960,
                // height: 700,
                
                // Factor of the display size that should remain empty around the content
                margin: 0.05,  // increase?

                // Bounds for smallest/largest possible scale to apply to content
                minScale: 0.5,
                maxScale: 5.0,

                theme: Reveal.getQueryHash().theme,  // available themes are in /css/theme
                transition: Reveal.getQueryHash().transition || 'none', // default/cube/page/concave/zoom/linear/fade/none

                // Push each slide change to the browser history
                history: true,
                // Enable keyboard shortcuts for navigation
                keyboard: true,

                // Vertical centering of slides
                center: true,

                // Enables touch navigation on devices with touch input
                touch: true,

                // Loop the presentation
                loop: false,
                // Flags if the presentation is running in an embedded mode,
                // i.e. contained within a limited portion of the screen
                embedded: false,

                // Number of milliseconds between automatically proceeding to the
                // next slide, disabled when set to 0, this value can be overwritten
                // by using a data-autoslide attribute on your slides
                autoSlide: 0,

                // Stop auto-sliding after user input
                autoSlideStoppable: true,

                // Enable slide navigation via mouse wheel
                mouseWheel: false,

                // Hides the address bar on mobile devices
                hideAddressBar: true,

                // Opens links in an iframe preview overlay
                previewLinks: false,

                // Transition speed
                transitionSpeed: 'default', // default/fast/slow

                // Transition style for full page slide backgrounds
                backgroundTransition: 'none', // default/none/slide/concave/convex/zoom

                // Number of slides away from the current that are visible
                viewDistance: 3,

                // Parallax background image
                //parallaxBackgroundImage: '', // e.g. "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'"

                // Parallax background size
                //parallaxBackgroundSize: '' // CSS syntax, e.g. "2100px 900px"

                // Optional libraries used to extend on reveal.js
                dependencies: [
                    { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
                    { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                    { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                    { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
                    { src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
                    { src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },
                    { src: 'plugin/math/math.js', async: true }
                ],

                math: {
                    mathjax: 'http://cdn.mathjax.org/mathjax/latest/MathJax.js',
                    config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
                }
            });

        </script>
        <script type="text/javascript"
    src="https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

    </body>
</html>
