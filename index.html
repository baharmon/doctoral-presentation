
<!-- Title -->
<section>
<img height="250px" src="img/tl_logo.png">
<h4 style="color: #888">Brendan Harmon</h4>
</section>

<!-- Spatial thinking -->
<section>
<h2>Spatial thinking</h2>
<p>`the mental processes of representing, analyzing, and drawing inferences from spatial relations'</p>
<p style="font-size:0.75em">Uttal, D. H., Miller, D. I., &amp Newcombe, N. S. (2013). <i>Exploring and Enhancing Spatial Thinking: Links to Achievement in Science, Technology, Engineering, and Mathematics?</i> Current Directions in Psychological Science, 22(5), 367–373. doi:10.1177/0963721413484756</a></p>
</section>

<!-- Spatial thinking -->
<section>
<h2>Spatial thinking</h2>
<p>Used pervasively in everyday life for tasks like
<ul>
<li>recognizing things,</li>
<li>manipulating things,</li>
<li>interacting with others,</li>
<li>and way-finding</li>
</ul>
</p>
</section>

<!-- Spatial thinking -->
<section data-background="img/jockeys_ridge_viz.jpg">
<h2 class="shadow">Spatial thinking in science, technology, engineering, and math</h2>
<p class="shadow">Used in diverse tasks including
<ul class="shadow">
<li>diagramming concepts,</li>
<li>visualizing data,</li>
<li>simulating processes,</li>
<li>and building structures</li>
</ul>
</p>
</section>

<!-- Spatial thinking -->
<section data-background="img/drawing_1.jpg">
<h2 class="shadow">Spatial thinking in art and design</h2>
<p class="shadow">Used in tasks including
<ul class="shadow">
<li>sketching,</li>
<li>form-finding,</li>
<li>and critical analysis</li>
</ul>
</p>
</section>

<!-- Spatial computation -->
<section data-background="img/skyview.png">
<h2 class="shadow">Spatial computation</h2>
<h3 class="shadow">Used to efficiently store, model, and analyze large sets of spatial data in order solve complex spatiotemporal problems</h3>
</section>

<!-- Human-computer interaction -->
<section>
<h2>Human-computer interaction</h2>
<h3 style="color: #888">Graphical user interfaces</h3>
<p>Parsing spatial data presented graphically requires sophisticated reasoning such as
<ul>
<li>mental rotation,</li>
<li>spatial visualization,</li>
<li>and spatial perception</li>
</ul>
</p>
</section>

<!-- Embodied cognition -->
<section data-background="img/physical_rotation_2.jpg">
<h2 class="shadow">Embodied cognition</h2>
<h3 class="shadow">Cognitive processes can be offloaded onto the body and physically simulated</h3>
<p class="shadow">Ex: Physically simulating mental rotation</p>
</section>

<!-- Tangible interface for GIS -->
<section>
<h2>Tangible interfaces for GIS</h2>
<p>Physically manifest geospatial data so that we can cognitively grasp and absorb it<p>
<img height="250px" src="img/logo_black.png">
<img height="250px" src="img/tl_logo.png">
</section>

<!-- Tangible Landscape -->
<section data-background="img/tangible_landscape.jpg">
<h1 class="shadow">Tangible Landscape</h1>
<h3 class="shadow">A tangible interface for GIS</h3>
<img height="150px" src="img/logo_black.png">
</section>

<!-- Tangible Landscape -->
<section data-background="img/tl_system_logo.png" data-background-size="auto 75%">
</section>

<!-- History -->
<section>
<h2>History</h2>
<img height="250px" src="img/illuminating_clay.png">
<img height="250px" src="img/tangeoms_2.jpg">
<p>An evolution of <b>Illuminating Clay</b> and the <b>Tangible Geospatial Modeling System</b></p>
<p style="font-size:0.75em"><a href="http://tmg-trackr.media.mit.edu/publishedmedia/Papers/249-Illuminating%20Clay%20A%20Tangible/Published/PDF">Piper, Ben, Carlo Ratti, and Hiroshi Ishii. 2002. “Illuminating Clay: A Tangible Interface with Potential GRASS Applications.” In Proceedings of the Open Source GIS - GRASS Users Conference 2002. Trento, Italy.</a></p>
<p style="font-size:0.75em"><a href="http://baharmon.github.io/publications/tangible_geospatial_modeling.pdf">L. Tateosian, H. Mitasova, B. A. Harmon, B. Fogleman, K. Weaver, and R. S. Harmon, “TanGeoMS: tangible geospatial modeling system.,” IEEE Trans. Vis. Comput. Graph., vol. 16, no. 6, pp. 1605–12, 2010.</a></p>
<p style="font-size:0.75em">Image source: <a href="http://tangible.media.mit.edu/project/illuminating-clay/">MIT Media Lab</a></p>
</section>

<!-- Near real time interaction -->
<section>
<h2>Tanigble interaction with GIS</h2>
<video  data-autoplay width="90%" style="margin-top: 1em" controls>
<source src="img/tl_dam.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>With Tangible Landscape you can hold a GIS in your hands - feeling the shape of the earth, sculpting its topography, and directing the flow of water.</p>
</section>

<!-- How it works -->
<section>
<h2>How-it-works</h2>
<img style="margin-top: 1em" height="500px" src="img/system_schema.png">
<p>Tangible Landscape couples a digital and a physical model through a continuous cycle of 3D scanning, geospatial modeling, and projection</p>
</section>

<!-- Science with Tangible Landscape -->
<section>
<h2>Intuitive scientific modeling</h2>
<img width="25%" src="img/subsurface_1.jpg">
<img width="25%" src="img/subsurface_2.jpg">
<img width="40.55%" src="img/subsurface_3.jpg">
<h4>Tangible Landscape is designed to make scientific models exploratory, engaging, and fun</h4>
<p>by enabling a rapid iterative process of observation, hypothesizing, testing, and inference</p>
</section>

<!-- Designing for performance -->
<section>
<h2>Geodesign</h2>
<img src="img/diagram_1.png">
<h3 style="margin-top: 0.25em">Designing performance landscapes</a></h3>
<h4 style="margin-top: 0.75em">through an iterative cycle of ideation, geospatial modeling, and critique</h4>
</section>

<!-- Visibility analysis -->
<section>
<h2>Applications</h2>
<video  data-autoplay width="90%" style="margin-top: 1em" controls>
<source src="img/visibility.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<h4 style="margin-top: 1em">Visibility analysis</h4>
</section>

<!-- Solar analysis-->
<section>
<h2>Applications</h2>
<img width="30%" src="img/solar_1.jpg">
<img width="30%" src="img/solar_2.jpg">
<img width="30%" src="img/solar_3.jpg">
<h4 style="margin-top: 1em">Solar analysis</h4>
<p>Solar irradiation and cast shadow</p>
</section>

<!-- Trail Planning -->
<section>
<h2>Applications</h2>
<img width="30%" src="img/trail_1.jpg">
<img width="30%" src="img/trail_2.jpg">
<img width="30%" src="img/trail_4.jpg">
<!--<img width="24%" src="img/trail_5.jpg">-->
<h4 style="margin-top: 1em">Trail planning</h4>
<p>Optimized trail routing between waypoints based on energetics, topography, and cost maps with feedback including trail slopes and viewsheds</p>
</section>

<!-- Serious gaming with Tangible Landscape: Coastal -->
<section>
<h2>Scientific gaming</h2>
<img width="30%" src="img/tl_coastal_1s.png">
<img width="30%" src="img/tl_coastal_2s.png">
<!--<img width="22%" src="img/tl_coastal_3s.png">-->
<img width="30%" src="img/tl_coastal_4s.png">
<h3 style="margin-top: 1em">Coastal flooding game</h3>
<h4>Save houses from coastal flooding by building coastal defenses</h4>
<p>Structured problem solving with rules, challenging objectives, and scoring</p>
</section>

<!-- Serious gaming with Tangible Landscape: Termites -->
<section>
<h2>Scientific gaming</h2>
<img width="30%" src="img/termite_game_1.jpg">
<img width="30%" src="img/termite_game_2.jpg">
<img width="30%" src="img/termite_game_3.jpg">
<h3 style="margin-top: 1em">Termite infestation game</h3>
<h4>Manage the spread of termites across a city by treating city blocks</h4>
<p>Explore the behavior of an epidemiological model through serious gaming</p>
</section>

<!-- Experiment -->

<!-- Research questions -->
<section>
<h2>Research questions</h2>
<p>
<ul>
<li>How can we design an effective tangible interface for GIS?</li>
<li>Can coupling a physical and digital model of topography improve spatial performance?</li>
<li>How do different geospatial analytics mediate users' spatial performance when using a tangible interface for GIS?</li>
</ul>
</p>
</section>

<!-- Coupling -->
<section>
<h2>Coupling experiment</h2>
<img width="26%" src="img/anderson_rhino.jpg">
<img width="32%" src="img/magallanes_hand.jpg">
<img width="32%" src="img/art_proj_aug.jpg">
<h4 style="margin-top: 1em">Can coupling a physical and digital model of topography improve spatial performance?</h4>
<p>A comparative study of 3D spatial performance with 1. digital modeling, 2. hand modeling, and 3. projection augmented modeling</p>
</section>

<!-- Coupling: mean elevation -->
<section>
<h2>Mean elevation</h2>
<img width="22.5%" src="img/results/dem_1.png">
<img width="22.5%" src="img/results/mean_dem_1.png">
<img width="22.5%" src="img/results/mean_dem_2.png">
<img width="22.5%" src="img/results/mean_dem_3.png">
<p>1. reference,  2. digital modeling, 3. hand modeling, and 4. projection augmented modeling</p>
</section>

<!-- Coupling: elevation difference -->
<section>
<h2>Mean difference in elevation</h2>
<img width="22.5%" src="img/results/dem_difference_1.png">
<img width="22.5%" src="img/results/mean_dem_difference_1.png">
<img width="22.5%" src="img/results/mean_dem_difference_2.png">
<img width="22.5%" src="img/results/mean_dem_difference_3.png">
<p>1. reference,  2. digital modeling, 3. hand modeling, and 4. projection augmented modeling</p>
</section>

<!-- Coupling: slope difference -->
<section>
<h2>Mean difference in slopes</h2>
<img width="22.5%" src="img/results/slope_difference_1.png">
<img width="22.5%" src="img/results/mean_slope_difference_1.png">
<img width="22.5%" src="img/results/mean_slope_difference_2.png">
<img width="22.5%" src="img/results/mean_slope_difference_3.png">
<p>1. reference,  2. digital modeling, 3. hand modeling, and 4. projection augmented modeling</p>
</section>

<!-- Coupling: depth difference -->
<section>
<h2>Mean difference in water depth</h2>
<img width="22.5%" src="img/results/depth_difference_1.png">
<img width="22.5%" src="img/results/mean_depth_difference_1.png">
<img width="22.5%" src="img/results/mean_depth_difference_2.png">
<img width="22.5%" src="img/results/mean_depth_difference_3.png">
<p>1. reference,  2. digital modeling, 3. hand modeling, and 4. projection augmented modeling</p>
</section>

<!-- Coupling: landforms difference
<section>
<h2>Mean difference in landforms</h2>
<img width="22.5%" src="img/results/forms_difference_1.png">
<img width="22.5%" src="img/results/mean_forms_difference_1.png">
<img width="22.5%" src="img/results/mean_forms_difference_2.png">
<img width="22.5%" src="img/results/mean_forms_difference_3.png">
<h4 style="margin-top: 1em"></h4>
<p>1. reference,  2. digital modeling, 3. hand modeling, and 4. projection augmented modeling</p>
</section>
 -->

<!-- Coupling: ridges difference -->
<section>
<h2>Mean difference in ridges</h2>
<img width="22.5%" src="img/results/ridges_1.png">
<img width="22.5%" src="img/results/mean_ridges_1.png">
<img width="22.5%" src="img/results/mean_ridges_2.png">
<img width="22.5%" src="img/results/mean_ridges_3.png">
<p>1. reference,  2. digital modeling, 3. hand modeling, and 4. projection augmented modeling</p>
</section>

<!-- Difference -->
<section>
<h2>Cut-fill experiment</h2>
<video  data-autoplay width="90%" style="margin-top: 1em" controls>
<source src="img/difference_analytic.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<h4>Building a terrain model in polymer-enriched sand using Tangible Landscape's differencing analytic (i.e. cut and fill) as a real-time guide.</h4>
<p>Blue means add more sand. Red means remove sand.</p>
</section>

<!-- Difference -->
<section>
<h2>Cut-fill experiment</h2>
<img width="22.5%" src="img/difference/tl_difference_1.jpg">
<img width="22.5%" src="img/difference/tl_difference_2.jpg">
<img width="22.5%" src="img/difference/tl_difference_3.jpg">
<img width="22.5%" src="img/difference/tl_difference_4.jpg">
<p style="margin-top: 1em">How does the difference analytic (ie. cut-fill) mediate users' spatial performance with a tangible interface for GIS?</p>
</section>

<!-- Difference: mean elevation -->
<section>
<h2>Mean elevation</h2>
<img width="48%" src="img/results/dem_4.png">
<img width="48%" src="img/results/mean_dem_4.png">
<p>1. reference and 2. cut-fill analytic</p>
</section>

<!-- Difference: elevation difference -->
<section>
<h2>Mean difference in elevation</h2>
<img width="48%" src="img/results/dem_difference_4.png">
<img width="48%" src="img/results/mean_dem_difference_4.png">
<p>1. reference and 2. cut-fill analytic</p>
</section>

<!-- Water flow -->
<section data-background="img/tl_water.jpg">
<h2 class="shadow">Water flow experiment</h2>
<p class="shadow" style="margin-top: 1em">How does the water flow analytic mediate users' spatial performance with a tangible interface for GIS?</p>
</section>


<!-- Water flow: depth -->
<section>
<h2>Mean water depth</h2>
<img width="48%" src="img/results/depth_5.png">
<img width="48%" src="img/results/mean_depth_5.png">
<p>1. reference and 2. water flow analytic</p>
</section>

<!-- Water flow: flow difference -->
<section>
<h2>Mean difference in water depth</h2>
<img width="48%" src="img/results/depth_difference_5.png">
<img width="48%" src="img/results/mean_depth_difference_5.png">
<p>1. reference and 2. water flow analytic</p>
</section>

<!-- Findings -->
<section>
<h2>Findings</h2>
<ul>
<li>This method of digital modeling tended to produce abstract approximations of the form</li>
<li>Hand modeling tended to produce rough, exaggerated models that represented many morphological features</li>
<li>Projection augmented modeling tended to produce relatively accurate models that better represented slope, water flow, and morphological features</li>
<li>The cut-fill analytic tended to produce very accurate models</li>
<li>The water flow analytic tended to produce accurately modeled stream channels, but more approximate topography elsewhere</li>
</ul>
</section>

<!-- Discussion -->
<section>
<h2>Observations</h2>
<ul>
<li>The cut-fill analytic enabled participants to generatively shape form and critically assess the results in an iterative cycle</li>
<li>The water flow simulation enabled an iterative cycle of form-finding and critical assessment that helped participants to learn how form controls process</li>
</ul>
</section>

<!-- Conclusion -->
<section>
<h2>Conclusions</h2>
<ul>
<li>Tangible Landscape encourages metacognitive processes</li>
<li>Tangible Landscape can increase users' spatial performance in different ways depending upon the analytics choosen</li>
<li>Tangible Landscape can help users link process to form</li>
</ul>
</section>

<!-- Implications -->
<section>
<h2>Implications</h2>
<ul>
<li>The cut-fill and water flow analytics could be used to teach grading and geomorphology</li>
</ul>
</section>

<!-- Summary -->

<!-- Publications -->
<section>
<h2>Publications</h2>
<ul>
<li>
Harmon, B. A., Petrasova, A., Petras, V., &amp Mitasova, H. (2016).
Computational Landscape Architecture: Procedural, Tangible, and Open Landscapes.
In J. R. Anderson & D. Ortega (Eds.), <a href="https://www.routledge.com/Innovations-in-Landscape-Architecture/Anderson-Ortega/p/book/9781138860681"><em>Innovations in Landscape Architecture</em></a>. Routledge.
</li>
<li>
Harmon, B. A., Petrasova, A., Petras, V., Mitasova, H., &amp Meentemeyer, R. K. (2016).
<a href="https://github.com/baharmon/isprs-2016/blob/master/isprs_2016.pdf">Tangible Landscape: cognitively grasping the flow of water</a>.
In <em>The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences</em>.
Prague: International Society of Photogrammetry and Remote Sensing.
</li>
<li>
Harmon, B. A. (2016).
<a href="http://dx.doi.org/10.1145/2839462.2854103">Embodied Spatial Thinking in Tangible Computing.</a>
In <em>TEI ’16: Proceedings of the Tenth International Conference on Tangible, Embedded, and Embodied Interaction </em> (pp. 693–696). Eindhoven, Netherlands: ACM Press. <a href="http://dx.doi.org/10.1145/2839462.2854103">http://dx.doi.org/10.1145/2839462.2854103</a>
</li>
<li>
Petrasova, A., Harmon, B., Petras, V., &amp Mitasova, H. (2015).
<em>Tangible Modeling with Open Source GIS.</em> Springer International Publishing.
<a href="http://dx.doi.org/10.1007/978-3-319-25775-4">http://dx.doi.org/10.1007/978-3-319-25775-4</a>
</li>
<li>
Petrasova, A., Harmon, B. A., Petras, V., &amp Mitasova, H. (2014).
<a href="http://www.iemss.org/sites/iemss2014/papers/iemss2014_submission_131.pdf">GIS-based environmental modeling with tangible interaction and dynamic visualization</a>.
In D. P. Ames &amp N. Quinn (Eds.), <em>Proceedings of the 7th International Congress on Environmental Modelling and Software</em>.
San Diego, California, USA: International Environmental Modelling and Software Society.
</li>
</ul>
</section>

<section>
<h2>Presentations</h2>
<ul>
<li>
Petrasova, A., Petras, V., Harmon, B. A., &amp Mitasova, H. (2016, May 2).
<a href="https://grasswiki.osgeo.org/wiki/Using_GRASS_GIS_through_Python_and_tangible_interfaces_(workshop_at_FOSS4G_NA_2016)"><em>Using GRASS GIS through Python and tangible interfaces</em></a>.
Workshop conducted at FOSS4G North America 2016, Raleigh, NC.
</li>
<li>
Harmon, B. A., Petrasova, A., Petras, V., Mitasova, H., &amp Meentemeyer, R. K. (2016, May 3).
<a href="http://baharmon.github.io/foss4g-na-2016/"><em>Tangible interaction for GIS</em></a>.
Presented at FOSS4G NA 2016, Raleigh, NC.
</li>
<li>
Harmon, B. A., Petrasova, A., Petras, V., Mitasova, H., &amp Meentemeyer, R. K. (2016, April 1).
<a href="http://baharmon.github.io/aag-2016/"><em>Creative spatial thinking with Tangible Landscape</em></a>.
Presented at American Association of Geographers Annual Meeting 2016, San Francisco, CA.
</li>
<li>
Harmon, B. A., Mitasova, H., &amp Petrasova, A. (2014, January 30).
<a href="http://video.esri.com/watch/3170/tangible-geospatial-modeling-for-landscape-architects"><em>Tangible geospatial modeling for landscape architects.</em></a>
Presented at 2014 Geodesign Summit, Redlands, CA.
</li>
</ul>
</section>

<!-- Timeline -->
<section>
<h2>Timeline</h2>
<table>
<tr><th>Date</th><th>Objective</th></tr>
<tr><td>May 31, 2016</td><td><b>Preliminary oral exam</b></td></tr>
<tr><td>July __, 2016</td><td>Submit paper to TOCHI</td></tr>
<tr><td>July 12 - 19, 2016</td><td>ISPRS conference</td></tr>
<tr><td>Aug 30 - Sept  2, 2016</td><td>RGS conference</td></tr>
<tr><td>September __, 2016</td><td><b>Doctoral exam</b></td></tr>
<tr><td>September __, 2016</td><td>Submit grading education paper</td></tr>
<tr><td>September 14, 2016</td><td>Apply for Marie Curie Fellowship</td></tr>
<tr><td>September 30, 2016</td><td>Apply for NGA Postdoctoral Fellowship</td></tr>
<tr><td>September __, 2016</td><td>Apply for Taubman College Research Fellowship</td></tr>
<tr><td>December 16, 2016</td><td><b>Graduation</b></td></tr>
<tr><td>January 12, 2017</td><td>Apply for NSF Robotics Initiative</td></tr>
</table>
</section>

<!-- Future work -->

<!-- Future work: cognitive science -->
<section data-background="img/tl_cog_sci.png">
<h2 class="shadow">Future work</h2>
<!-- <p class="shadow" style="margin-top: 1em">Cognitive science experiments to study metacognition and learning with Tangible Landscape</p> -->
</section>

<!-- Future work: in-situ digital fabrication -->
<section>
<h2>Future work</h2>
<video  data-autoplay width="90%" style="margin-top: 1em" controls>
<source src="img/cnc_sand.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<h4>In-situ digital fabrication</h4>
<p>A 3-axis CNC milling machine to model a landscape in polymer-enriched sand using a plunge cut</p>
</section>

<!-- Future work: robotic fabrication -->
<section>
<h2>Future work</h2>
<img style="margin-top: 1em" height="500px" src="img/system_schema_robot.png">
<p>In-situ robotic fabrication for Tangible Landscape</p>
</section>

<!-- Future work: VR -->
<section>
<h2>Future work</h2>
<img style="margin-top: 1em" height="500px" src="img/system_schema_vr.png">
<p>Virtual reality for Tangible Landscape</p>
</section>

<!-- Future work: autonomous construction -->
<section>
<h2>Future work</h2>
<img style="margin-top: 1em" width="100%" src="img/system_schema_land.png">
<p>Real-time data and autonomous construction with Tangible Landscape</p>
</section>

<!-- Experiment: open science
<section>
<h2>Open science</h2>
<img width="10%" src="img/Octocat.png">
<h4 style="margin-top: 1em">Fork us on GitHub</h4>
<p><a href="https://github.com/baharmon/tangible_topography">Repository with experiment instructions, scripts, data, and results</a></p>
<p><a href="https://github.com/ncsu-osgeorel/grass-tangible-landscape">Repository for the Tangible Landscape plugin for GRASS GIS</a></p>
</section>
-->

<!-- Open education
<section>
<h2>Open education</h2>
<img height="150px" src="img/logo_black.png">
<h4 style="margin-top: 1em">Open source software, open algorithms, open data, and open educational resources</h4>
<p>
Petras, V., Petrasova, A., Harmon, B., Meentemeyer, R.K., Mitasova, H.
<a href="http://www.mdpi.com/2220-9964/4/2/942/pdf"><em>
Integrating Free and Open Source Solutions into Geospatial Science Education</em></a>.
ISPRS International Journal of Geo-Information. 2015, 4, 942-956.
<a href="http://dx.doi.org/10.3390/ijgi4020942">doi:10.3390/ijgi4020942</a>
</p>
</section>
-->

<!-- Book
<section>
<h2>Set up your own system</h2>
<img width="20%" src="img/tl_book_cover.png">
<p>Read our <a href="http://www.springer.com/us/book/9783319257730">book</a> and give it a try</p>
</section>
-->

<!-- Future work: cognitive science
<section>
<h2>Future work</h2>
<img width="90%" src="img/future_system.png">
<p>Experiments using eye trackers, EEGs, and biometric sensors to study learning and creativity with Tangible Landscape</p>
</section>
-->

<!-- Future work: digital fabrication
<section>
<h2>Future work</h2>
<video  data-autoplay width="90%" style="margin-top: 1em" controls>
<source src="img/cnc_sand.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>In situ digital fabrication</p>
</section>
-->

<!-- Discussion -->
