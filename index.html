
<!-- Title -->
<section>
<img height="250px" src="img/tl_logo.png">
<h4 style="color: #888">Brendan Harmon</h4>
</section>

<!-- Spatial thinking -->
<section>
<h2>Spatial thinking</h2>
<p>`the mental processes of representing, analyzing, and drawing inferences from spatial relations'</p>
<p style="font-size:0.75em">Uttal, D. H., Miller, D. I., &amp Newcombe, N. S. (2013). <i>Exploring and Enhancing Spatial Thinking: Links to Achievement in Science, Technology, Engineering, and Mathematics?</i> Current Directions in Psychological Science, 22(5), 367–373. doi:10.1177/0963721413484756</a></p>
</section>

<!-- Spatial thinking -->
<section>
<h2>Spatial thinking</h2>
<p>Used pervasively in everyday life for tasks like
<ul>
<li>recognizing things,</li>
<li>manipulating things,</li>
<li>interacting with others,</li>
<li>and way-finding</li>
</ul>
</p>
</section>

<!-- Spatial thinking -->
<section data-background="img/jockeys_ridge_viz.jpg">
<h2 class="shadow">Spatial thinking in science, technology, engineering, and math</h2>
<p class="shadow">Used in diverse tasks including
<ul class="shadow">
<li>diagramming concepts,</li>
<li>visualizing data,</li>
<li>simulating processes,</li>
<li>and building structures</li>
</ul>
</p>
</section>

<!-- Spatial thinking -->
<section data-background="img/drawing_1.jpg">
<h2 class="shadow">Spatial thinking in art and design</h2>
<p class="shadow">Used in tasks including
<ul class="shadow">
<li>sketching,</li>
<li>form-finding,</li>
<li>and critical analysis</li>
</ul>
</p>
</section>

<!-- Spatial computation -->
<section data-background="img/skyview.png">
<h2 class="shadow">Spatial computation</h2>
<h3 class="shadow">Used to efficiently store, model, and analyze large sets of spatial data in order solve complex spatiotemporal problems</h3>
</section>

<!-- Human-computer interaction -->
<section>
<h2>Human-computer interaction</h2>
<h3 style="color: #888">Graphical user interfaces</h3>
<p>Parsing spatial data presented graphically requires sophisticated reasoning such as
<ul>
<li>mental rotation,</li>
<li>spatial visualization,</li>
<li>and spatial perception</li>
</ul>
</p>
</section>

<!-- Embodied cognition -->
<section data-background="img/physical_rotation_2.jpg">
<h2 class="shadow">Embodied cognition</h2>
<h3 class="shadow">Cognitive processes can be offloaded onto the body and physically simulated</h3>
<p class="shadow">Ex: Physically simulating mental rotation</p>
</section>

<!-- Tangible interface for GIS -->
<section>
<h2>Tangible interfaces for GIS</h2>
<p>Physically manifest geospatial data so that we can cognitively grasp and absorb it<p>
<img height="250px" src="img/logo_black.png">
<img height="250px" src="img/tl_logo.png">
</section>

<!-- Tangible Landscape -->
<section data-background="img/tangible_landscape.jpg">
<h1 class="shadow">Tangible Landscape</h1>
<h3 class="shadow">A tangible interface for GIS</h3>
<img height="150px" src="img/logo_black.png">
</section>

<!-- Tangible Landscape -->
<section data-background="img/tl_system_logo.png" data-background-size="auto 75%">
</section>

<!-- History -->
<section>
<h2>History</h2>
<img height="250px" src="img/illuminating_clay.png">
<img height="250px" src="img/tangeoms_2.jpg">
<p>An evolution of <b>Illuminating Clay</b> and the <b>Tangible Geospatial Modeling System</b></p>
<p style="font-size:0.75em"><a href="http://tmg-trackr.media.mit.edu/publishedmedia/Papers/249-Illuminating%20Clay%20A%20Tangible/Published/PDF">Piper, Ben, Carlo Ratti, and Hiroshi Ishii. 2002. “Illuminating Clay: A Tangible Interface with Potential GRASS Applications.” In Proceedings of the Open Source GIS - GRASS Users Conference 2002. Trento, Italy.</a></p>
<p style="font-size:0.75em"><a href="http://baharmon.github.io/publications/tangible_geospatial_modeling.pdf">L. Tateosian, H. Mitasova, B. A. Harmon, B. Fogleman, K. Weaver, and R. S. Harmon, “TanGeoMS: tangible geospatial modeling system.,” IEEE Trans. Vis. Comput. Graph., vol. 16, no. 6, pp. 1605–12, 2010.</a></p>
<p style="font-size:0.75em">Image source: <a href="http://tangible.media.mit.edu/project/illuminating-clay/">MIT Media Lab</a></p>
</section>

<!-- Near real time interaction -->
<section>
<h2>Tanigble interaction with GIS</h2>
<video  data-autoplay width="90%" style="margin-top: 1em" controls>
<source src="img/tl_dam.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>With Tangible Landscape you can hold a GIS in your hands - feeling the shape of the earth, sculpting its topography, and directing the flow of water.</p>
</section>

<!-- How it works -->
<section>
<h2>How-it-works</h2>
<img style="margin-top: 1em" height="500px" src="img/system_schema.png">
<p>Tangible Landscape couples a digital and a physical model through a continuous cycle of 3D scanning, geospatial modeling, and projection</p>
</section>

<!-- Science with Tangible Landscape -->
<section>
<h2>Intuitive scientific modeling</h2>
<img width="25%" src="img/subsurface_1.jpg">
<img width="25%" src="img/subsurface_2.jpg">
<img width="40.55%" src="img/subsurface_3.jpg">
<h4>Tangible Landscape is designed to make scientific models exploratory, engaging, and fun</h4>
<p>by enabling a rapid iterative process of observation, hypothesizing, testing, and inference</p>
</section>

<!-- Designing for performance -->
<section>
<h2>Geodesign</h2>
<img src="img/diagram_1.png">
<h3 style="margin-top: 0.25em">Designing performance landscapes</a></h3>
<h4 style="margin-top: 0.75em">through an iterative cycle of ideation, geospatial modeling, and critique</h4>
</section>

<!-- Visibility analysis -->
<section>
<h2>Applications</h2>
<video  data-autoplay width="90%" style="margin-top: 1em" controls>
<source src="img/visibility.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<h4 style="margin-top: 1em">Visibility analysis</h4>
</section>

<!-- Solar analysis-->
<section>
<h2>Applications</h2>
<img width="30%" src="img/solar_1.jpg">
<img width="30%" src="img/solar_2.jpg">
<img width="30%" src="img/solar_3.jpg">
<h4 style="margin-top: 1em">Solar analysis</h4>
<p>Solar irradiation and cast shadow</p>
</section>

<!-- Trail Planning -->
<section>
<h2>Applications</h2>
<img width="30%" src="img/trail_1.jpg">
<img width="30%" src="img/trail_2.jpg">
<img width="30%" src="img/trail_4.jpg">
<!--<img width="24%" src="img/trail_5.jpg">-->
<h4 style="margin-top: 1em">Trail planning</h4>
<p>Optimized trail routing between waypoints based on energetics, topography, and cost maps with feedback including trail slopes and viewsheds</p>
</section>

<!-- Serious gaming with Tangible Landscape: Coastal -->
<section>
<h2>Scientific gaming</h2>
<img width="30%" src="img/tl_coastal_1s.png">
<img width="30%" src="img/tl_coastal_2s.png">
<!--<img width="22%" src="img/tl_coastal_3s.png">-->
<img width="30%" src="img/tl_coastal_4s.png">
<h3 style="margin-top: 1em">Coastal flooding game</h3>
<h4>Save houses from coastal flooding by building coastal defenses</h4>
<p>Structured problem solving with rules, challenging objectives, and scoring</p>
</section>

<!-- Serious gaming with Tangible Landscape: Termites -->
<section>
<h2>Scientific gaming</h2>
<img width="30%" src="img/termite_game_1.jpg">
<img width="30%" src="img/termite_game_2.jpg">
<img width="30%" src="img/termite_game_3.jpg">
<h3 style="margin-top: 1em">Termite infestation game</h3>
<h4>Manage the spread of termites across a city by treating city blocks</h4>
<p>Explore the behavior of an epidemiological model through serious gaming</p>
</section>

<!-- Experiment -->

<!-- Research questions -->
<section>
<h2>Research questions</h2>
<p>
<ul>
<li>How can we design an effective tangible interface for GIS?</li>
<li>Can coupling a physical and digital model of topography improve spatial performance?</li>
<li>How do different geospatial analytics mediate users' spatial performance when using a tangible interface for GIS?</li>
</ul>
</p>
</section>

<!-- Coupling -->
<section>
<h2>Coupling experiment</h2>
<img width="30%" src="img/anderson_rhino.jpg">
<img width="30%" src="img/magallanes_hand.jpg">
<img width="30%" src="img/art_proj_aug.jpg">
<h4 style="margin-top: 1em">Can coupling a physical and digital model of topography improve spatial performance?</h4>
<p>A comparative study of 3D spatial performance with 1. digital modeling, 2. hand modeling, and 3. projection augmented modeling</p>
</section>

<!-- Coupling: mean elevation -->
<section>
<h2>Mean elevation</h2>
<img width="22.5%" src="img/results/dem_1.png">
<img width="22.5%" src="img/results/mean_dem_1.png">
<img width="22.5%" src="img/results/mean_dem_2.png">
<img width="22.5%" src="img/results/mean_dem_3.png">
<h4 style="margin-top: 1em"></h4>
<p>1. reference,  2. digital modeling, 3. hand modeling, and 4. projection augmented modeling</p>
</section>

<!-- Coupling: elevation difference -->
<section>
<h2>Mean difference in elevation</h2>
<img width="22.5%" src="img/results/dem_difference_1.png">
<img width="22.5%" src="img/results/mean_dem_difference_1.png">
<img width="22.5%" src="img/results/mean_dem_difference_2.png">
<img width="22.5%" src="img/results/mean_dem_difference_3.png">
<h4 style="margin-top: 1em"></h4>
<p>1. reference,  2. digital modeling, 3. hand modeling, and 4. projection augmented modeling</p>
</section>

<!-- Coupling: slope difference -->
<section>
<h2>Mean difference in slopes</h2>
<img width="22.5%" src="img/results/slope_difference_1.png">
<img width="22.5%" src="img/results/mean_slope_difference_1.png">
<img width="22.5%" src="img/results/mean_slope_difference_2.png">
<img width="22.5%" src="img/results/mean_slope_difference_3.png">
<h4 style="margin-top: 1em"></h4>
<p>1. reference,  2. digital modeling, 3. hand modeling, and 4. projection augmented modeling</p>
</section>

<!-- Coupling: depth difference -->
<section>
<h2>Mean difference in water depth</h2>
<img width="22.5%" src="img/results/depth_difference_1.png">
<img width="22.5%" src="img/results/mean_depth_difference_1.png">
<img width="22.5%" src="img/results/mean_depth_difference_2.png">
<img width="22.5%" src="img/results/mean_depth_difference_3.png">
<h4 style="margin-top: 1em"></h4>
<p>1. reference,  2. digital modeling, 3. hand modeling, and 4. projection augmented modeling</p>
</section>

<!-- Coupling: landforms difference -->
<section>
<h2>Mean difference in landforms</h2>
<img width="22.5%" src="img/results/forms_difference_1.png">
<img width="22.5%" src="img/results/mean_forms_difference_1.png">
<img width="22.5%" src="img/results/mean_forms_difference_2.png">
<img width="22.5%" src="img/results/mean_forms_difference_3.png">
<h4 style="margin-top: 1em"></h4>
<p>1. reference,  2. digital modeling, 3. hand modeling, and 4. projection augmented modeling</p>
</section>

<!-- Coupling: ridges difference -->
<section>
<h2>Mean difference in ridges</h2>
<img width="22.5%" src="img/results/ridges_1.png">
<img width="22.5%" src="img/results/mean_ridges_1.png">
<img width="22.5%" src="img/results/mean_ridges_2.png">
<img width="22.5%" src="img/results/mean_ridges_3.png">
<h4 style="margin-top: 1em"></h4>
<p>1. reference,  2. digital modeling, 3. hand modeling, and 4. projection augmented modeling</p>
</section>

<!-- Difference -->
<section>
<h2>Cut-fill experiment</h2>
<video  data-autoplay width="90%" style="margin-top: 1em" controls>
<source src="img/difference_analytic.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<h4 style="margin-top: 1em">How does the difference analytic (ie. cut-fill) mediate users' spatial performance with a tangible interface for GIS?</h4>
<p>Building a terrain model in polymer-enriched sand using Tangible Landscape's differencing analytic (i.e. cut and fill) as a real-time guide.</p>
<p>Blue means add more sand. Red means remove sand.</p>
</section>

<!-- Difference -->
<section>
<h2>Cut-fill experiment</h2>
<img width="22.5%" src="img/difference/tl_difference_1.jpg">
<img width="22.5%" src="img/difference/tl_difference_2.jpg">
<img width="22.5%" src="img/difference/tl_difference_3.jpg">
<img width="22.5%" src="img/difference/tl_difference_4.jpg">
<h4 style="margin-top: 1em">How does the difference analytic (ie. cut-fill) mediate users' spatial performance with a tangible interface for GIS?</h4>
<p>Building a terrain model in polymer-enriched sand using Tangible Landscape's differencing analytic (i.e. cut and fill) as a real-time guide.</p>
<p>Blue means add more sand. Red means remove sand.</p>
</section>

<!-- Difference: mean elevation -->
<section>
<h2>Mean elevation</h2>
<img width="48%" src="img/results/dem_4.png">
<img width="48%" src="img/results/mean_dem_4.png">
<h4 style="margin-top: 1em"></h4>
<p>1. reference and 2. cut-fill analytic</p>
</section>

<!-- Difference: elevation difference -->
<section>
<h2>Mean difference in elevation</h2>
<img width="48%" src="img/results/dem_difference_4.png">
<img width="48%" src="img/results/mean_dem_difference_4.png">
<h4 style="margin-top: 1em"></h4>
<p>1. reference and 2. cut-fill analytic</p>
</section>

<!-- Water flow -->
<section data-background="img/tl_water.jpg">
<h2 class="shadow">Water flow experiment</h2>
<p class="shadow" style="margin-top: 1em">How does the water flow analytic mediate users' spatial performance with a tangible interface for GIS?</p>
</section>

<!-- Water flow -->
<section>
<h2>Water flow experiment</h2>
<img src="img/difference/tl_water.jpg">
<p class="shadow" style="margin-top: 1em">How does the water flow analytic mediate users' spatial performance with a tangible interface for GIS?</p>
</section>

<!-- Water flow: flow -->
<section>
<h2>Mean water depth</h2>
<img width="48%" src="img/results/depth_5.png">
<img width="48%" src="img/results/mean_depth_5.png">
<h4 style="margin-top: 1em"></h4>
<p>1. reference and 2. water flow analytic</p>
</section>

<!-- Water flow: flow difference -->
<section>
<h2>Mean difference in water depth</h2>
<img width="48%" src="img/results/depth_difference_5.png">
<img width="48%" src="img/results/mean_depth_difference_5.png">
<h4 style="margin-top: 1em"></h4>
<p>1. reference and 2. water flow analytic</p>
</section>

<!-- Discussion -->
<section>
<h2>Discussion</h2>
<p>Tangible Landscape's cut-fill analytic enabled participants to generatively shape form and critically assess the results in an iterative cycle</p>
<p>Tangible Landscape's water flow simulation enabled an iterative cycle of form-finding and critical assessment that helped participants to learn how form controls process</p>
</section>

<!-- Conclusion -->

<!-- Summary -->

<!-- Publications -->
<!-- http://baharmon.github.io/publications.html -->
<!-- http://tangible-landscape.github.io/ -->


<!-- Timeline -->


<!-- Future work -->

<!-- Future work: in-situ digital fabrication -->
<section>
<h2>Future work</h2>
<video  data-autoplay width="90%" style="margin-top: 1em" controls>
<source src="img/cnc_sand.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<h4>In-situ digital fabrication</h4>
<p>A 3-axis CNC milling machine to model a landscape in polymer-enriched sand using a plunge cut</p>
</section>

<!-- Future work: robotic fabrication -->
<section>
<h2>Future work</h2>
<img style="margin-top: 1em" height="500px" src="img/system_schema_robot.png">
<p>In-situ robotic fabrication for Tangible Landscape</p>
</section>

<!-- Future work: VR -->
<section>
<h2>Future work</h2>
<img style="margin-top: 1em" height="500px" src="img/system_schema_vr.png">
<p>Virtual reality for Tangible Landscape</p>
</section>

<!-- Future work: autonomous construction -->
<section>
<h2>Future work</h2>
<img style="margin-top: 1em" width="100%" src="img/system_schema_land.png">
<p>Real-time data and autonomous construction with Tangible Landscape</p>
</section>




<!-- Experiment: open science
<section>
<h2>Open science</h2>
<img width="10%" src="img/Octocat.png">
<h4 style="margin-top: 1em">Fork us on GitHub</h4>
<p><a href="https://github.com/baharmon/tangible_topography">Repository with experiment instructions, scripts, data, and results</a></p>
<p><a href="https://github.com/ncsu-osgeorel/grass-tangible-landscape">Repository for the Tangible Landscape plugin for GRASS GIS</a></p>
</section>
-->

<!-- Open education
<section>
<h2>Open education</h2>
<img height="150px" src="img/logo_black.png">
<h4 style="margin-top: 1em">Open source software, open algorithms, open data, and open educational resources</h4>
<p>
Petras, V., Petrasova, A., Harmon, B., Meentemeyer, R.K., Mitasova, H.
<a href="http://www.mdpi.com/2220-9964/4/2/942/pdf"><em>
Integrating Free and Open Source Solutions into Geospatial Science Education</em></a>.
ISPRS International Journal of Geo-Information. 2015, 4, 942-956.
<a href="http://dx.doi.org/10.3390/ijgi4020942">doi:10.3390/ijgi4020942</a>
</p>
</section>
-->

<!-- Book
<section>
<h2>Set up your own system</h2>
<img width="20%" src="img/tl_book_cover.png">
<p>Read our <a href="http://www.springer.com/us/book/9783319257730">book</a> and give it a try</p>
</section>
-->

<!-- Future work: cognitive science
<section>
<h2>Future work</h2>
<img width="90%" src="img/future_system.png">
<p>Experiments using eye trackers, EEGs, and biometric sensors to study learning and creativity with Tangible Landscape</p>
</section>
-->

<!-- Future work: digital fabrication
<section>
<h2>Future work</h2>
<video  data-autoplay width="90%" style="margin-top: 1em" controls>
<source src="img/cnc_sand.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>In situ digital fabrication</p>
</section>
-->

<!-- Discussion -->
